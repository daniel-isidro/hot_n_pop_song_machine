{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ColumnTransformer to mixed column data types, and using pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could handle transformations directly when training the model. With ```ColumnTransform``` we can apply ```OneHotEncoder``` to categorical columns and ```RobustScaler``` (which is more robust to outliers than other transformations) to numerical columns. Let's go back to the original dataset to practice this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data_prep/hot_plus_random.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>uri</th>\n",
       "      <th>track_href</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.565</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.722</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.5790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.252</td>\n",
       "      <td>75.018</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>1MOqMyQ7CULmWWjovkFY5B</td>\n",
       "      <td>spotify:track:1MOqMyQ7CULmWWjovkFY5B</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/1MOqMyQ7CULm...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/1MOq...</td>\n",
       "      <td>209320.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.578</td>\n",
       "      <td>0.894</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-5.420</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.741</td>\n",
       "      <td>165.980</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>2dwhMQsFeHr2S787WxqAqW</td>\n",
       "      <td>spotify:track:2dwhMQsFeHr2S787WxqAqW</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/2dwhMQsFeHr2...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/2dwh...</td>\n",
       "      <td>347107.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.529</td>\n",
       "      <td>0.496</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-9.007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.278</td>\n",
       "      <td>136.859</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>3y4LxiYMgDl4RethdzpmNe</td>\n",
       "      <td>spotify:track:3y4LxiYMgDl4RethdzpmNe</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/3y4LxiYMgDl4...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/3y4L...</td>\n",
       "      <td>250547.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.488</td>\n",
       "      <td>0.923</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.697</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.818</td>\n",
       "      <td>183.891</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>296XGtH5MeGisqD3uAz6Q6</td>\n",
       "      <td>spotify:track:296XGtH5MeGisqD3uAz6Q6</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/296XGtH5MeGi...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/296X...</td>\n",
       "      <td>202253.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.753</td>\n",
       "      <td>0.450</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.2740</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.560</td>\n",
       "      <td>109.405</td>\n",
       "      <td>audio_features</td>\n",
       "      <td>6kD36kVRn5leDDbjXpHQY0</td>\n",
       "      <td>spotify:track:6kD36kVRn5leDDbjXpHQY0</td>\n",
       "      <td>https://api.spotify.com/v1/tracks/6kD36kVRn5le...</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6kD3...</td>\n",
       "      <td>288933.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   danceability  energy   key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.565   0.547   0.0    -7.722   1.0       0.0347        0.5790   \n",
       "1         0.578   0.894  10.0    -5.420   1.0       0.0296        0.0103   \n",
       "2         0.529   0.496   7.0    -9.007   1.0       0.0290        0.1730   \n",
       "3         0.488   0.923   2.0    -3.697   1.0       0.1030        0.1290   \n",
       "4         0.753   0.450   9.0    -6.909   1.0       0.0924        0.2740   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo            type  \\\n",
       "0          0.000000     0.194    0.252   75.018  audio_features   \n",
       "1          0.000003     0.216    0.741  165.980  audio_features   \n",
       "2          0.000000     0.251    0.278  136.859  audio_features   \n",
       "3          0.000000     0.158    0.818  183.891  audio_features   \n",
       "4          0.000002     0.321    0.560  109.405  audio_features   \n",
       "\n",
       "                       id                                   uri  \\\n",
       "0  1MOqMyQ7CULmWWjovkFY5B  spotify:track:1MOqMyQ7CULmWWjovkFY5B   \n",
       "1  2dwhMQsFeHr2S787WxqAqW  spotify:track:2dwhMQsFeHr2S787WxqAqW   \n",
       "2  3y4LxiYMgDl4RethdzpmNe  spotify:track:3y4LxiYMgDl4RethdzpmNe   \n",
       "3  296XGtH5MeGisqD3uAz6Q6  spotify:track:296XGtH5MeGisqD3uAz6Q6   \n",
       "4  6kD36kVRn5leDDbjXpHQY0  spotify:track:6kD36kVRn5leDDbjXpHQY0   \n",
       "\n",
       "                                          track_href  \\\n",
       "0  https://api.spotify.com/v1/tracks/1MOqMyQ7CULm...   \n",
       "1  https://api.spotify.com/v1/tracks/2dwhMQsFeHr2...   \n",
       "2  https://api.spotify.com/v1/tracks/3y4LxiYMgDl4...   \n",
       "3  https://api.spotify.com/v1/tracks/296XGtH5MeGi...   \n",
       "4  https://api.spotify.com/v1/tracks/6kD36kVRn5le...   \n",
       "\n",
       "                                        analysis_url  duration_ms  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/1MOq...     209320.0   \n",
       "1  https://api.spotify.com/v1/audio-analysis/2dwh...     347107.0   \n",
       "2  https://api.spotify.com/v1/audio-analysis/3y4L...     250547.0   \n",
       "3  https://api.spotify.com/v1/audio-analysis/296X...     202253.0   \n",
       "4  https://api.spotify.com/v1/audio-analysis/6kD3...     288933.0   \n",
       "\n",
       "   time_signature  success  \n",
       "0             4.0      1.0  \n",
       "1             4.0      1.0  \n",
       "2             4.0      1.0  \n",
       "3             4.0      1.0  \n",
       "4             4.0      1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15714, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "danceability        float64\n",
       "energy              float64\n",
       "key                 float64\n",
       "loudness            float64\n",
       "mode                float64\n",
       "speechiness         float64\n",
       "acousticness        float64\n",
       "instrumentalness    float64\n",
       "liveness            float64\n",
       "valence             float64\n",
       "tempo               float64\n",
       "type                 object\n",
       "id                   object\n",
       "uri                  object\n",
       "track_href           object\n",
       "analysis_url         object\n",
       "duration_ms         float64\n",
       "time_signature      float64\n",
       "success             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
       "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
       "       'type', 'id', 'uri', 'track_href', 'analysis_url', 'duration_ms',\n",
       "       'time_signature', 'success'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Using StandardScaler and OneHotEncoder (dropping the first column to avoid collinearity in logistic reg.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.886\n",
      "cross_val score: 0.880\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88      1574\n",
      "         1.0       0.85      0.94      0.89      1569\n",
      "\n",
      "    accuracy                           0.89      3143\n",
      "   macro avg       0.89      0.89      0.89      3143\n",
      "weighted avg       0.89      0.89      0.89      3143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "# Now we have a full prediction pipeline\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(max_iter=1000, n_jobs=-1))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"accuracy score: %.3f\" % clf.score(X_test, y_test))\n",
    "print(\"cross_val score: %.3f\" % cross_val_score(clf,X,y,cv=5,scoring=\"accuracy\", n_jobs=-1).mean())\n",
    "print(\"\\n\", classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using StandardScaler and OneHotEncoder (all columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.886\n",
      "cross_val score: 0.880\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.83      0.88      1558\n",
      "         1.0       0.85      0.95      0.89      1585\n",
      "\n",
      "    accuracy                           0.89      3143\n",
      "   macro avg       0.89      0.89      0.89      3143\n",
      "weighted avg       0.89      0.89      0.89      3143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "# Now we have a full prediction pipeline\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(max_iter=1000, n_jobs=-1))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"accuracy score: %.3f\" % clf.score(X_test, y_test))\n",
    "print(\"cross_val score: %.3f\" % cross_val_score(clf,X,y,cv=5,scoring=\"accuracy\", n_jobs=-1).mean())\n",
    "print(\"\\n\", classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RobustScaler and OneHotEncoder (dropping the first column to avoid collinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.885\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88      1540\n",
      "         1.0       0.85      0.94      0.89      1603\n",
      "\n",
      "    accuracy                           0.89      3143\n",
      "   macro avg       0.89      0.88      0.88      3143\n",
      "weighted avg       0.89      0.89      0.88      3143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "# Now we have a full prediction pipeline\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(max_iter=1000, n_jobs=-1))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"accuracy score: %.3f\" % clf.score(X_test, y_test))\n",
    "print(\"\\n\", classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using RobustScaler (which handles better the outliers) and OneHotEncoder() maintaining all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.879\n",
      "cross_val score: 0.880\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.82      0.88      1635\n",
      "         1.0       0.83      0.94      0.88      1508\n",
      "\n",
      "    accuracy                           0.88      3143\n",
      "   macro avg       0.88      0.88      0.88      3143\n",
      "weighted avg       0.89      0.88      0.88      3143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "# Now we have a full prediction pipeline\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(max_iter=1000, n_jobs=-1))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"accuracy score: %.3f\" % clf.score(X_test, y_test))\n",
    "print(\"cross_val score: %.3f\" % cross_val_score(clf,X,y,cv=5,scoring=\"accuracy\", n_jobs=-1).mean())\n",
    "print(\"\\n\", classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing purposes: using OrdinalEncoding on categorical features (instead of OneHotEncoding) and StandardScaler in the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.881\n",
      "cross_val score: 0.879\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.83      0.87      1541\n",
      "         1.0       0.85      0.93      0.89      1602\n",
      "\n",
      "    accuracy                           0.88      3143\n",
      "   macro avg       0.89      0.88      0.88      3143\n",
      "weighted avg       0.88      0.88      0.88      3143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('ordinal', OrdinalEncoder())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "# Now we have a full prediction pipeline\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(max_iter=1000, n_jobs=-1))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"accuracy score: %.3f\" % clf.score(X_test, y_test))\n",
    "print(\"cross_val score: %.3f\" % cross_val_score(clf,X,y,cv=5,scoring=\"accuracy\", n_jobs=-1).mean())\n",
    "print(\"\\n\", classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RobustScaler and OneHotEncoder (dropping the first column to avoid collinearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.883\n",
      "cross_val score: 0.879\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.83      0.88      1574\n",
      "         1.0       0.85      0.93      0.89      1569\n",
      "\n",
      "    accuracy                           0.88      3143\n",
      "   macro avg       0.89      0.88      0.88      3143\n",
      "weighted avg       0.89      0.88      0.88      3143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline\n",
    "# Now we have a full prediction pipeline\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', KNeighborsClassifier(n_neighbors=10, n_jobs=-1))])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"accuracy score: %.3f\" % clf.score(X_test, y_test))\n",
    "print(\"cross_val score: %.3f\" % cross_val_score(clf,X,y,cv=5,scoring=\"accuracy\", n_jobs=-1).mean())\n",
    "print(\"\\n\", classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using pipelines with GridSearchCV\n",
    "\n",
    "Reference: https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'classifier__n_neighbors': 12}\n",
      "best score: 0.880\n",
      "accuracy score: 0.885\n",
      "cross_val score: 0.879\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.82      0.88      1596\n",
      "         1.0       0.83      0.95      0.89      1547\n",
      "\n",
      "    accuracy                           0.88      3143\n",
      "   macro avg       0.89      0.89      0.88      3143\n",
      "weighted avg       0.89      0.88      0.88      3143\n",
      "\n",
      "CPU times: user 4.37 s, sys: 220 ms, total: 4.59 s\n",
      "Wall time: 9min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "param_grid = {'classifier__n_neighbors': np.arange(4,100)}\n",
    "\n",
    "\n",
    "CV = GridSearchCV(clf, param_grid, n_jobs=-1)\n",
    "\n",
    "CV.fit(X_train, y_train)\n",
    "print('best params: ', CV.best_params_)    \n",
    "print('best score: %.3f' % CV.best_score_)\n",
    "\n",
    "print('accuracy score: %.3f' % CV.score(X_test, y_test))\n",
    "print('cross_val score: %.3f' % cross_val_score(CV,X,y,cv=5,scoring='accuracy', n_jobs=-1).mean())\n",
    "print('\\n', classification_report(y_test,CV.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Classifier\n",
    "### RobustScaler, OneHotEncoder, Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'classifier__C': 10, 'classifier__gamma': 'auto', 'classifier__tol': 0.001}\n",
      "best score: 0.891\n",
      "accuracy score: 0.891\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.83      0.89      1589\n",
      "         1.0       0.85      0.95      0.90      1554\n",
      "\n",
      "    accuracy                           0.89      3143\n",
      "   macro avg       0.90      0.89      0.89      3143\n",
      "weighted avg       0.90      0.89      0.89      3143\n",
      "\n",
      "CPU times: user 3.75 s, sys: 173 ms, total: 3.92 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', SVC())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "param_grid = {'classifier__C': [.1, 1, 10, 100],\n",
    "             'classifier__gamma': ['auto'],\n",
    "              'classifier__tol': [.001]}\n",
    "\n",
    "CV = GridSearchCV(clf, \n",
    "                  param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  n_jobs=-1)\n",
    "\n",
    "CV.fit(X_train, y_train)\n",
    "print('best params: ', CV.best_params_)    \n",
    "print('best score: %.3f' % CV.best_score_)\n",
    "\n",
    "print('accuracy score: %.3f' % CV.score(X_test, y_test))\n",
    "#print('cross_val score: %.3f' % cross_val_score(CV,X,y,cv=5,scoring='accuracy', n_jobs=-1).mean())\n",
    "print('\\n', classification_report(y_test,CV.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier\n",
    "### RobustScaler, OneHotEncoder, Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'classifier__max_depth': 9, 'classifier__min_samples_leaf': 12}\n",
      "best score: 0.884\n",
      "accuracy score: 0.877\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.82      0.87      1589\n",
      "         1.0       0.84      0.93      0.88      1554\n",
      "\n",
      "    accuracy                           0.88      3143\n",
      "   macro avg       0.88      0.88      0.88      3143\n",
      "weighted avg       0.88      0.88      0.88      3143\n",
      "\n",
      "CPU times: user 38.1 s, sys: 2.99 s, total: 41.1 s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop=None, handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "param_grid = {'classifier__max_depth': np.arange(2,20),\n",
    "              'classifier__min_samples_leaf': np.arange(0,100)}\n",
    "\n",
    "CV = GridSearchCV(clf, \n",
    "                  param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  n_jobs=-1)\n",
    "\n",
    "CV.fit(X_train, y_train)\n",
    "print('best params: ', CV.best_params_)    \n",
    "print('best score: %.3f' % CV.best_score_)\n",
    "\n",
    "print('accuracy score: %.3f' % CV.score(X_test, y_test))\n",
    "#print('cross_val score: %.3f' % cross_val_score(CV,X,y,cv=5,scoring='accuracy', n_jobs=-1).mean())\n",
    "print('\\n', classification_report(y_test,CV.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "### RobustScaler, OneHotEncoder, Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'classifier__criterion': 'entropy', 'classifier__max_depth': 25, 'classifier__max_features': 'auto', 'classifier__n_estimators': 150, 'classifier__random_state': 0}\n",
      "best score: 0.904\n",
      "accuracy score: 0.905\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.86      0.90      1584\n",
      "         1.0       0.87      0.95      0.91      1559\n",
      "\n",
      "    accuracy                           0.90      3143\n",
      "   macro avg       0.91      0.91      0.90      3143\n",
      "weighted avg       0.91      0.90      0.90      3143\n",
      "\n",
      "CPU times: user 7.45 s, sys: 267 ms, total: 7.71 s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop=None, handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', RandomForestClassifier())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "param_grid = {'classifier__n_estimators': [50, 100, 150, 200, 250],\n",
    "              'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'classifier__max_depth': [10, 15, 20, 25, 30],\n",
    "              'classifier__criterion': ['gini', 'entropy'],\n",
    "              'classifier__random_state': [0]}\n",
    "\n",
    "CV = GridSearchCV(clf, \n",
    "                  param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  n_jobs=-1)\n",
    "\n",
    "CV.fit(X_train, y_train)\n",
    "print('best params: ', CV.best_params_)    \n",
    "print('best score: %.3f' % CV.best_score_)\n",
    "\n",
    "print('accuracy score: %.3f' % CV.score(X_test, y_test))\n",
    "#print('cross_val score: %.3f' % cross_val_score(CV,X,y,cv=5,scoring='accuracy', n_jobs=-1).mean())\n",
    "print('\\n', classification_report(y_test,CV.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Classifier\n",
    "### RobustScaler, OneHotEncoder, Pipeline and GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params:  {'classifier__colsample_bytree': 0.8, 'classifier__gamma': 1, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 5, 'classifier__n_estimators': 1000, 'classifier__subsample': 1}\n",
      "best score: 0.906\n",
      "accuracy score: 0.894\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.84      0.89      1554\n",
      "         1.0       0.86      0.94      0.90      1589\n",
      "\n",
      "    accuracy                           0.89      3143\n",
      "   macro avg       0.90      0.89      0.89      3143\n",
      "weighted avg       0.90      0.89      0.89      3143\n",
      "\n",
      "CPU times: user 18.2 s, sys: 118 ms, total: 18.3 s\n",
      "Wall time: 8min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "X = df.drop(['type', 'id', 'uri', 'track_href', 'analysis_url', 'success'], axis=1)\n",
    "y = df['success']\n",
    "numeric_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', RobustScaler())])\n",
    "\n",
    "categorical_features = ['key', 'mode', 'time_signature']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=np.nan)),\n",
    "    ('onehot', OneHotEncoder(drop='first', handle_unknown='error'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', XGBClassifier())])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "\n",
    "param_grid = {'classifier__learning_rate': [0.1, 0.01],\n",
    "              'classifier__n_estimators': [1000],\n",
    "              'classifier__max_depth': [3, 4, 5],\n",
    "              'classifier__subsample': [0.8, 1],\n",
    "              'classifier__colsample_bytree': [0.8, 1],\n",
    "              'classifier__gamma': [1]}\n",
    "\n",
    "CV = GridSearchCV(clf, \n",
    "                  param_grid,\n",
    "                  scoring='accuracy',\n",
    "                  n_jobs=-1)\n",
    "\n",
    "CV.fit(X_train, y_train)\n",
    "print('best params: ', CV.best_params_)    \n",
    "print('best score: %.3f' % CV.best_score_)\n",
    "\n",
    "print('accuracy score: %.3f' % CV.score(X_test, y_test))\n",
    "#print('cross_val score: %.3f' % cross_val_score(CV,X,y,cv=5,scoring='accuracy', n_jobs=-1).mean())\n",
    "print('\\n', classification_report(y_test,CV.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
